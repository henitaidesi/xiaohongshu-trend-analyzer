#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨ - å®ç°æ•°æ®çš„å®æ—¶æ›´æ–°
"""

import time
import threading
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, Callable
import schedule
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.triggers.cron import CronTrigger

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from real_xhs_crawler import RealXhsCrawler
from database_manager import db_manager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SchedulerService:
    def __init__(self):
        """åˆå§‹åŒ–è°ƒåº¦å™¨æœåŠ¡"""
        self.scheduler = BackgroundScheduler()
        self.crawler = RealXhsCrawler()
        self.running = False
        self.stats = {
            'total_runs': 0,
            'successful_runs': 0,
            'failed_runs': 0,
            'last_run': None,
            'next_run': None
        }
        
        # é…ç½®ä»»åŠ¡
        self.setup_jobs()
    
    def setup_jobs(self):
        """è®¾ç½®å®šæ—¶ä»»åŠ¡"""
        
        # 1. æ¯30åˆ†é’Ÿæ›´æ–°çƒ­é—¨è¯é¢˜
        self.scheduler.add_job(
            func=self.update_hot_topics,
            trigger=IntervalTrigger(minutes=30),
            id='update_hot_topics',
            name='æ›´æ–°çƒ­é—¨è¯é¢˜',
            max_instances=1,
            replace_existing=True
        )
        
        # 2. æ¯å°æ—¶æ›´æ–°çƒ­é—¨å…³é”®è¯
        self.scheduler.add_job(
            func=self.update_trending_keywords,
            trigger=IntervalTrigger(hours=1),
            id='update_keywords',
            name='æ›´æ–°çƒ­é—¨å…³é”®è¯',
            max_instances=1,
            replace_existing=True
        )
        
        # 3. æ¯å¤©å‡Œæ™¨2ç‚¹è¿›è¡Œæ•°æ®æ¸…ç†
        self.scheduler.add_job(
            func=self.cleanup_old_data,
            trigger=CronTrigger(hour=2, minute=0),
            id='cleanup_data',
            name='æ¸…ç†æ—§æ•°æ®',
            max_instances=1,
            replace_existing=True
        )
        
        # 4. æ¯6å°æ—¶ç”Ÿæˆåˆ†ææŠ¥å‘Š
        self.scheduler.add_job(
            func=self.generate_analysis_report,
            trigger=IntervalTrigger(hours=6),
            id='generate_report',
            name='ç”Ÿæˆåˆ†ææŠ¥å‘Š',
            max_instances=1,
            replace_existing=True
        )
        
        # 5. æ¯åˆ†é’Ÿæ£€æŸ¥ç³»ç»ŸçŠ¶æ€ï¼ˆç”¨äºæ¼”ç¤ºï¼‰
        self.scheduler.add_job(
            func=self.health_check,
            trigger=IntervalTrigger(minutes=5),
            id='health_check',
            name='ç³»ç»Ÿå¥åº·æ£€æŸ¥',
            max_instances=1,
            replace_existing=True
        )
        
        logger.info("âœ… å®šæ—¶ä»»åŠ¡é…ç½®å®Œæˆ")
    
    def update_hot_topics(self):
        """æ›´æ–°çƒ­é—¨è¯é¢˜"""
        try:
            logger.info("ğŸ”¥ å¼€å§‹æ›´æ–°çƒ­é—¨è¯é¢˜...")
            
            # è·å–çƒ­é—¨å…³é”®è¯
            keywords = self.crawler.get_trending_keywords()
            
            # çˆ¬å–æ¯ä¸ªå…³é”®è¯çš„çƒ­é—¨å†…å®¹
            all_notes = []
            for keyword_data in keywords[:5]:  # åªçˆ¬å–å‰5ä¸ªå…³é”®è¯
                keyword = keyword_data['keyword']
                notes = self.crawler.search_notes(keyword, limit=10)
                all_notes.extend(notes)
                time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            if db_manager.connected or True:  # æ€»æ˜¯å°è¯•ä¿å­˜
                db_manager.save_notes(all_notes)
            
            self.stats['successful_runs'] += 1
            self.stats['last_run'] = datetime.now()
            
            logger.info(f"âœ… çƒ­é—¨è¯é¢˜æ›´æ–°å®Œæˆï¼Œè·å– {len(all_notes)} æ¡æ•°æ®")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°çƒ­é—¨è¯é¢˜å¤±è´¥: {e}")
            self.stats['failed_runs'] += 1
        
        self.stats['total_runs'] += 1
    
    def update_trending_keywords(self):
        """æ›´æ–°çƒ­é—¨å…³é”®è¯"""
        try:
            logger.info("ğŸ” å¼€å§‹æ›´æ–°çƒ­é—¨å…³é”®è¯...")
            
            # è·å–æœ€æ–°çš„çƒ­é—¨å…³é”®è¯
            keywords = self.crawler.get_trending_keywords()
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            if db_manager.connected or True:
                db_manager.save_keywords(keywords)
            
            logger.info(f"âœ… çƒ­é—¨å…³é”®è¯æ›´æ–°å®Œæˆï¼Œè·å– {len(keywords)} ä¸ªå…³é”®è¯")
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°çƒ­é—¨å…³é”®è¯å¤±è´¥: {e}")
    
    def cleanup_old_data(self):
        """æ¸…ç†æ—§æ•°æ®"""
        try:
            logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†æ—§æ•°æ®...")
            
            # è¿™é‡Œå¯ä»¥å®ç°æ¸…ç†é€»è¾‘
            # ä¾‹å¦‚ï¼šåˆ é™¤30å¤©å‰çš„æ•°æ®
            cutoff_date = datetime.now() - timedelta(days=30)
            
            # å¦‚æœä½¿ç”¨MongoDBï¼Œå¯ä»¥åˆ é™¤æ—§æ•°æ®
            # if db_manager.connected:
            #     db_manager.db[db_manager.collections['notes']].delete_many({
            #         'crawl_time': {'$lt': cutoff_date.isoformat()}
            #     })
            
            logger.info("âœ… æ—§æ•°æ®æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†æ—§æ•°æ®å¤±è´¥: {e}")
    
    def generate_analysis_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        try:
            logger.info("ğŸ“Š å¼€å§‹ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
            
            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = db_manager.get_statistics()
            
            # ç”ŸæˆæŠ¥å‘Š
            report = {
                'timestamp': datetime.now().isoformat(),
                'database_stats': stats,
                'scheduler_stats': self.stats.copy(),
                'system_status': 'healthy' if self.running else 'stopped'
            }
            
            # ä¿å­˜æŠ¥å‘Š
            import json
            import os
            
            reports_dir = os.path.join(os.path.dirname(__file__), 'reports')
            os.makedirs(reports_dir, exist_ok=True)
            
            report_file = os.path.join(reports_dir, f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report_file}")
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
    
    def health_check(self):
        """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
        try:
            logger.info("ğŸ’“ æ‰§è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥...")
            
            # æ£€æŸ¥æ•°æ®åº“è¿æ¥
            db_status = "connected" if db_manager.connected else "file_storage"
            
            # æ£€æŸ¥æœ€è¿‘çš„æ•°æ®æ›´æ–°æ—¶é—´
            notes = db_manager.get_notes(limit=1)
            last_data_update = "unknown"
            if notes:
                last_data_update = notes[0].get('crawl_time', 'unknown')
            
            # è®°å½•å¥åº·çŠ¶æ€
            health_status = {
                'timestamp': datetime.now().isoformat(),
                'database_status': db_status,
                'last_data_update': last_data_update,
                'scheduler_running': self.running,
                'total_jobs': len(self.scheduler.get_jobs())
            }
            
            logger.info(f"ğŸ’š ç³»ç»Ÿå¥åº·çŠ¶æ€: {health_status}")
            
        except Exception as e:
            logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
    
    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        try:
            # è¿æ¥æ•°æ®åº“
            db_manager.connect()
            
            # å¯åŠ¨è°ƒåº¦å™¨
            self.scheduler.start()
            self.running = True
            
            logger.info("ğŸš€ å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å¯åŠ¨æˆåŠŸ")
            logger.info("ğŸ“‹ å·²é…ç½®çš„ä»»åŠ¡:")
            
            for job in self.scheduler.get_jobs():
                logger.info(f"   - {job.name} (ID: {job.id})")
                logger.info(f"     ä¸‹æ¬¡æ‰§è¡Œ: {job.next_run_time}")
            
            # ç«‹å³æ‰§è¡Œä¸€æ¬¡æ•°æ®æ›´æ–°ï¼ˆç”¨äºæ¼”ç¤ºï¼‰
            logger.info("ğŸ¯ ç«‹å³æ‰§è¡Œä¸€æ¬¡æ•°æ®æ›´æ–°...")
            self.update_trending_keywords()
            self.update_hot_topics()
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨è°ƒåº¦å™¨å¤±è´¥: {e}")
            self.running = False
    
    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        try:
            self.scheduler.shutdown()
            self.running = False
            db_manager.close()
            
            logger.info("ğŸ›‘ å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")
            
        except Exception as e:
            logger.error(f"âŒ åœæ­¢è°ƒåº¦å™¨å¤±è´¥: {e}")
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–è°ƒåº¦å™¨çŠ¶æ€"""
        jobs_info = []
        for job in self.scheduler.get_jobs():
            jobs_info.append({
                'id': job.id,
                'name': job.name,
                'next_run': job.next_run_time.isoformat() if job.next_run_time else None,
                'trigger': str(job.trigger)
            })
        
        return {
            'running': self.running,
            'stats': self.stats,
            'jobs': jobs_info,
            'database_connected': db_manager.connected
        }
    
    def run_job_now(self, job_id: str) -> bool:
        """ç«‹å³æ‰§è¡ŒæŒ‡å®šä»»åŠ¡"""
        try:
            job = self.scheduler.get_job(job_id)
            if job:
                job.modify(next_run_time=datetime.now())
                logger.info(f"âœ… ä»»åŠ¡ {job_id} å·²å®‰æ’ç«‹å³æ‰§è¡Œ")
                return True
            else:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°ä»»åŠ¡: {job_id}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}")
            return False

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
scheduler_service = SchedulerService()

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºè°ƒåº¦å™¨åŠŸèƒ½"""
    print("ğŸš€ å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨...")
    
    try:
        # å¯åŠ¨è°ƒåº¦å™¨
        scheduler_service.start()
        
        # è¿è¡Œä¸€æ®µæ—¶é—´ç”¨äºæ¼”ç¤º
        print("â° è°ƒåº¦å™¨è¿è¡Œä¸­ï¼ŒæŒ‰ Ctrl+C åœæ­¢...")
        
        # æ˜¾ç¤ºçŠ¶æ€
        import time
        for i in range(10):  # è¿è¡Œ10æ¬¡æ£€æŸ¥ï¼Œæ¯æ¬¡é—´éš”30ç§’
            time.sleep(30)
            status = scheduler_service.get_status()
            print(f"\nğŸ“Š è°ƒåº¦å™¨çŠ¶æ€ (ç¬¬{i+1}æ¬¡æ£€æŸ¥):")
            print(f"   è¿è¡ŒçŠ¶æ€: {'âœ… è¿è¡Œä¸­' if status['running'] else 'âŒ å·²åœæ­¢'}")
            print(f"   æ€»ä»»åŠ¡æ•°: {len(status['jobs'])}")
            print(f"   æ‰§è¡Œç»Ÿè®¡: {status['stats']}")
            
            # æ˜¾ç¤ºä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
            for job in status['jobs']:
                if job['next_run']:
                    print(f"   - {job['name']}: {job['next_run']}")
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·...")
    finally:
        scheduler_service.stop()
        print("âœ… è°ƒåº¦å™¨å·²å®‰å…¨åœæ­¢")

if __name__ == "__main__":
    main()
